AdaptiveSparkPlan isFinalPlan=true
+- == Final Plan ==
   NativeTakeOrdered 100, [lochierarchy#1 DESC NULLS LAST, CASE WHEN (lochierarchy#1 = 0) THEN i_category#2 END ASC NULLS FIRST, rank_within_parent#3 ASC NULLS FIRST]
   +- NativeProject [gross_margin#4, i_category#2, i_class#5, lochierarchy#1, rank_within_parent#3]
      +- NativeWindow [rank(_w0#6) windowspecdefinition(_w1#7, _w2#8, _w0#6 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#3], [_w1#7, _w2#8], [_w0#6 ASC NULLS FIRST]
         +- NativeSort [_w1#7 ASC NULLS FIRST, _w2#8 ASC NULLS FIRST, _w0#6 ASC NULLS FIRST], false
            +- InputAdapter
               +- AQEShuffleRead coalesced
                  +- ShuffleQueryStage X
                     +- NativeShuffleExchange hashpartitioning(_w1#7, _w2#8, 100), ENSURE_REQUIREMENTS, [plan_id=1]
                        +- NativeProject [(MakeDecimal(sum(UnscaledValue(ss_net_profit#9))#10,17,2) / MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#11))#12,17,2)) AS gross_margin#4, i_category#2, i_class#5, (cast((shiftright(spark_grouping_id#13, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#13, 0) & 1) as tinyint)) AS lochierarchy#1, (MakeDecimal(sum(UnscaledValue(ss_net_profit#9))#10,17,2) / MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#11))#12,17,2)) AS _w0#6, (cast((shiftright(spark_grouping_id#13, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#13, 0) & 1) as tinyint)) AS _w1#7, CASE WHEN (cast((shiftright(spark_grouping_id#13, 0) & 1) as tinyint) = 0) THEN i_category#2 END AS _w2#8]
                           +- NativeHashAggregate HashAgg, List(i_category#2, i_class#5, spark_grouping_id#13), [i_category#2, i_class#5, spark_grouping_id#13], [sum(UnscaledValue(ss_net_profit#9)), sum(UnscaledValue(ss_ext_sales_price#11))], [sum(UnscaledValue(ss_net_profit#9))#10, sum(UnscaledValue(ss_ext_sales_price#11))#12], 3
                              +- InputAdapter
                                 +- AQEShuffleRead coalesced
                                    +- ShuffleQueryStage X
                                       +- NativeShuffleExchange hashpartitioning(i_category#2, i_class#5, spark_grouping_id#13, 100), ENSURE_REQUIREMENTS, [plan_id=2]
                                          +- NativeHashAggregate HashAgg, [i_category#2, i_class#5, spark_grouping_id#13], [partial_sum(_c3#14), partial_sum(_c4#15)], [sum#16, sum#17], 0
                                             +- NativeProject [i_category#2 AS i_category#2, i_class#5 AS i_class#5, spark_grouping_id#13 AS spark_grouping_id#13, UnscaledValue(ss_net_profit#9) AS _c3#14, UnscaledValue(ss_ext_sales_price#11) AS _c4#15]
                                                +- !NativeExpand [[ss_ext_sales_price#11, ss_net_profit#9, i_category#18, i_class#19, 0], [ss_ext_sales_price#11, ss_net_profit#9, i_category#18, null, 1], [ss_ext_sales_price#11, ss_net_profit#9, null, null, 3]], [ss_ext_sales_price#11, ss_net_profit#9, i_category#2, i_class#5, spark_grouping_id#13]
                                                   +- NativeProject [ss_ext_sales_price#11, ss_net_profit#9, i_category#18, i_class#19]
                                                      +- NativeSortMergeJoin [ss_store_sk#20], [s_store_sk#21], Inner
                                                         :- NativeSort [ss_store_sk#20 ASC NULLS FIRST], false
                                                         :  +- InputAdapter
                                                         :     +- AQEShuffleRead coalesced
                                                         :        +- ShuffleQueryStage X
                                                         :           +- NativeShuffleExchange hashpartitioning(ss_store_sk#20, 100), ENSURE_REQUIREMENTS, [plan_id=3]
                                                         :              +- NativeProject [ss_store_sk#20, ss_ext_sales_price#11, ss_net_profit#9, i_class#19, i_category#18]
                                                         :                 +- NativeSortMergeJoin [ss_item_sk#22], [i_item_sk#23], Inner
                                                         :                    :- NativeSort [ss_item_sk#22 ASC NULLS FIRST], false
                                                         :                    :  +- InputAdapter
                                                         :                    :     +- AQEShuffleRead coalesced
                                                         :                    :        +- ShuffleQueryStage X
                                                         :                    :           +- NativeShuffleExchange hashpartitioning(ss_item_sk#22, 100), ENSURE_REQUIREMENTS, [plan_id=4]
                                                         :                    :              +- NativeProject [ss_item_sk#22, ss_store_sk#20, ss_ext_sales_price#11, ss_net_profit#9]
                                                         :                    :                 +- NativeSortMergeJoin [ss_sold_date_sk#24], [d_date_sk#25], Inner
                                                         :                    :                    :- NativeSort [ss_sold_date_sk#24 ASC NULLS FIRST], false
                                                         :                    :                    :  +- InputAdapter
                                                         :                    :                    :     +- AQEShuffleRead coalesced
                                                         :                    :                    :        +- ShuffleQueryStage X
                                                         :                    :                    :           +- NativeShuffleExchange hashpartitioning(ss_sold_date_sk#24, 100), ENSURE_REQUIREMENTS, [plan_id=5]
                                                         :                    :                    :              +- NativeFilter ((isnotnull(ss_sold_date_sk#24) AND isnotnull(ss_item_sk#22)) AND isnotnull(ss_store_sk#20))
                                                         :                    :                    :                 +- InputAdapter [#24, #22, #20, #11, #9]
                                                         :                    :                    :                    +- NativeParquetScan  (FileScan parquet [ss_sold_date_sk#24,ss_item_sk#22,ss_store_sk#20,ss_ext_sales_price#11,ss_net_profit#9] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#24), isnotnull(ss_item_sk#22), isnotnull(ss_store_sk#20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_item_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_store_sk:int,ss_ext_sales_price:decimal(7,2),ss_net_...)
                                                         :                    :                    +- NativeSort [d_date_sk#25 ASC NULLS FIRST], false
                                                         :                    :                       +- InputAdapter
                                                         :                    :                          +- AQEShuffleRead coalesced
                                                         :                    :                             +- ShuffleQueryStage X
                                                         :                    :                                +- NativeShuffleExchange hashpartitioning(d_date_sk#25, 100), ENSURE_REQUIREMENTS, [plan_id=6]
                                                         :                    :                                   +- NativeProject [d_date_sk#25]
                                                         :                    :                                      +- NativeFilter ((isnotnull(d_year#26) AND (d_year#26 = 2001)) AND isnotnull(d_date_sk#25))
                                                         :                    :                                         +- InputAdapter [#25, #26]
                                                         :                    :                                            +- NativeParquetScan  (FileScan parquet [d_date_sk#25,d_year#26] Batched: true, DataFilters: [isnotnull(d_year#26), (d_year#26 = 2001), isnotnull(d_date_sk#25)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2001), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>)
                                                         :                    +- NativeSort [i_item_sk#23 ASC NULLS FIRST], false
                                                         :                       +- InputAdapter
                                                         :                          +- AQEShuffleRead coalesced
                                                         :                             +- ShuffleQueryStage X
                                                         :                                +- NativeShuffleExchange hashpartitioning(i_item_sk#23, 100), ENSURE_REQUIREMENTS, [plan_id=7]
                                                         :                                   +- NativeFilter isnotnull(i_item_sk#23)
                                                         :                                      +- InputAdapter [#23, #19, #18]
                                                         :                                         +- NativeParquetScan  (FileScan parquet [i_item_sk#23,i_class#19,i_category#18] Batched: true, DataFilters: [isnotnull(i_item_sk#23)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_class:string,i_category:string>)
                                                         +- NativeSort [s_store_sk#21 ASC NULLS FIRST], false
                                                            +- InputAdapter
                                                               +- AQEShuffleRead coalesced
                                                                  +- ShuffleQueryStage X
                                                                     +- NativeShuffleExchange hashpartitioning(s_store_sk#21, 100), ENSURE_REQUIREMENTS, [plan_id=8]
                                                                        +- NativeProject [s_store_sk#21]
                                                                           +- NativeFilter ((isnotnull(s_state#27) AND (s_state#27 = TN)) AND isnotnull(s_store_sk#21))
                                                                              +- InputAdapter [#21, #27]
                                                                                 +- NativeParquetScan  (FileScan parquet [s_store_sk#21,s_state#27] Batched: true, DataFilters: [isnotnull(s_state#27), (s_state#27 = TN), isnotnull(s_store_sk#21)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(s_state), EqualTo(s_state,TN), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>)
+- == Initial Plan ==
   TakeOrderedAndProject(limit=100, orderBy=[lochierarchy#1 DESC NULLS LAST,CASE WHEN (lochierarchy#1 = 0) THEN i_category#2 END ASC NULLS FIRST,rank_within_parent#3 ASC NULLS FIRST], output=[gross_margin#4,i_category#2,i_class#5,lochierarchy#1,rank_within_parent#3])
   +- Project [gross_margin#4, i_category#2, i_class#5, lochierarchy#1, rank_within_parent#3]
      +- Window [rank(_w0#6) windowspecdefinition(_w1#7, _w2#8, _w0#6 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#3], [_w1#7, _w2#8], [_w0#6 ASC NULLS FIRST]
         +- Sort [_w1#7 ASC NULLS FIRST, _w2#8 ASC NULLS FIRST, _w0#6 ASC NULLS FIRST], false, 0
            +- Exchange hashpartitioning(_w1#7, _w2#8, 100), ENSURE_REQUIREMENTS, [plan_id=9]
               +- HashAggregate(keys=[i_category#2, i_class#5, spark_grouping_id#13], functions=[sum(UnscaledValue(ss_net_profit#9)), sum(UnscaledValue(ss_ext_sales_price#11))], output=[gross_margin#4, i_category#2, i_class#5, lochierarchy#1, _w0#6, _w1#7, _w2#8])
                  +- Exchange hashpartitioning(i_category#2, i_class#5, spark_grouping_id#13, 100), ENSURE_REQUIREMENTS, [plan_id=10]
                     +- HashAggregate(keys=[i_category#2, i_class#5, spark_grouping_id#13], functions=[partial_sum(UnscaledValue(ss_net_profit#9)), partial_sum(UnscaledValue(ss_ext_sales_price#11))], output=[i_category#2, i_class#5, spark_grouping_id#13, sum#28, sum#29])
                        +- Expand [[ss_ext_sales_price#11, ss_net_profit#9, i_category#18, i_class#19, 0], [ss_ext_sales_price#11, ss_net_profit#9, i_category#18, null, 1], [ss_ext_sales_price#11, ss_net_profit#9, null, null, 3]], [ss_ext_sales_price#11, ss_net_profit#9, i_category#2, i_class#5, spark_grouping_id#13]
                           +- Project [ss_ext_sales_price#11, ss_net_profit#9, i_category#18, i_class#19]
                              +- SortMergeJoin [ss_store_sk#20], [s_store_sk#21], Inner
                                 :- Sort [ss_store_sk#20 ASC NULLS FIRST], false, 0
                                 :  +- Exchange hashpartitioning(ss_store_sk#20, 100), ENSURE_REQUIREMENTS, [plan_id=11]
                                 :     +- Project [ss_store_sk#20, ss_ext_sales_price#11, ss_net_profit#9, i_class#19, i_category#18]
                                 :        +- SortMergeJoin [ss_item_sk#22], [i_item_sk#23], Inner
                                 :           :- Sort [ss_item_sk#22 ASC NULLS FIRST], false, 0
                                 :           :  +- Exchange hashpartitioning(ss_item_sk#22, 100), ENSURE_REQUIREMENTS, [plan_id=12]
                                 :           :     +- Project [ss_item_sk#22, ss_store_sk#20, ss_ext_sales_price#11, ss_net_profit#9]
                                 :           :        +- SortMergeJoin [ss_sold_date_sk#24], [d_date_sk#25], Inner
                                 :           :           :- Sort [ss_sold_date_sk#24 ASC NULLS FIRST], false, 0
                                 :           :           :  +- Exchange hashpartitioning(ss_sold_date_sk#24, 100), ENSURE_REQUIREMENTS, [plan_id=13]
                                 :           :           :     +- Filter ((isnotnull(ss_sold_date_sk#24) AND isnotnull(ss_item_sk#22)) AND isnotnull(ss_store_sk#20))
                                 :           :           :        +- FileScan parquet [ss_sold_date_sk#24,ss_item_sk#22,ss_store_sk#20,ss_ext_sales_price#11,ss_net_profit#9] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#24), isnotnull(ss_item_sk#22), isnotnull(ss_store_sk#20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_item_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_store_sk:int,ss_ext_sales_price:decimal(7,2),ss_net_...
                                 :           :           +- Sort [d_date_sk#25 ASC NULLS FIRST], false, 0
                                 :           :              +- Exchange hashpartitioning(d_date_sk#25, 100), ENSURE_REQUIREMENTS, [plan_id=14]
                                 :           :                 +- Project [d_date_sk#25]
                                 :           :                    +- Filter ((isnotnull(d_year#26) AND (d_year#26 = 2001)) AND isnotnull(d_date_sk#25))
                                 :           :                       +- FileScan parquet [d_date_sk#25,d_year#26] Batched: true, DataFilters: [isnotnull(d_year#26), (d_year#26 = 2001), isnotnull(d_date_sk#25)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2001), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
                                 :           +- Sort [i_item_sk#23 ASC NULLS FIRST], false, 0
                                 :              +- Exchange hashpartitioning(i_item_sk#23, 100), ENSURE_REQUIREMENTS, [plan_id=15]
                                 :                 +- Filter isnotnull(i_item_sk#23)
                                 :                    +- FileScan parquet [i_item_sk#23,i_class#19,i_category#18] Batched: true, DataFilters: [isnotnull(i_item_sk#23)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_class:string,i_category:string>
                                 +- Sort [s_store_sk#21 ASC NULLS FIRST], false, 0
                                    +- Exchange hashpartitioning(s_store_sk#21, 100), ENSURE_REQUIREMENTS, [plan_id=16]
                                       +- Project [s_store_sk#21]
                                          +- Filter ((isnotnull(s_state#27) AND (s_state#27 = TN)) AND isnotnull(s_store_sk#21))
                                             +- FileScan parquet [s_store_sk#21,s_state#27] Batched: true, DataFilters: [isnotnull(s_state#27), (s_state#27 = TN), isnotnull(s_store_sk#21)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<dir>], PartitionFilters: [], PushedFilters: [IsNotNull(s_state), EqualTo(s_state,TN), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>
