AdaptiveSparkPlan isFinalPlan=true
+- == Final Plan ==
   NativeTakeOrdered 100, [lochierarchy#1 DESC NULLS LAST, CASE WHEN (lochierarchy#1 = 0) THEN s_state#2 END ASC NULLS FIRST, rank_within_parent#3 ASC NULLS FIRST]
   +- NativeProject [total_sum#4, s_state#2, s_county#5, lochierarchy#1, rank_within_parent#3]
      +- NativeWindow [rank(_w0#6) windowspecdefinition(_w1#7, _w2#8, _w0#6 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#3], [_w1#7, _w2#8], [_w0#6 DESC NULLS LAST]
         +- NativeSort [_w1#7 ASC NULLS FIRST, _w2#8 ASC NULLS FIRST, _w0#6 DESC NULLS LAST], false
            +- InputAdapter
               +- AQEShuffleRead coalesced
                  +- ShuffleQueryStage X
                     +- NativeShuffleExchange hashpartitioning(_w1#7, _w2#8, 100), ENSURE_REQUIREMENTS, [plan_id=1]
                        +- NativeProject [MakeDecimal(sum(UnscaledValue(ss_net_profit#9))#10,17,2) AS total_sum#4, s_state#2, s_county#5, (cast((shiftright(spark_grouping_id#11, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#11, 0) & 1) as tinyint)) AS lochierarchy#1, MakeDecimal(sum(UnscaledValue(ss_net_profit#9))#10,17,2) AS _w0#6, (cast((shiftright(spark_grouping_id#11, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#11, 0) & 1) as tinyint)) AS _w1#7, CASE WHEN (cast((shiftright(spark_grouping_id#11, 0) & 1) as tinyint) = 0) THEN s_state#2 END AS _w2#8]
                           +- NativeHashAggregate HashAgg, List(s_state#2, s_county#5, spark_grouping_id#11), [s_state#2, s_county#5, spark_grouping_id#11], [sum(UnscaledValue(ss_net_profit#9))], [sum(UnscaledValue(ss_net_profit#9))#10], 3
                              +- InputAdapter
                                 +- AQEShuffleRead coalesced
                                    +- ShuffleQueryStage X
                                       +- NativeShuffleExchange hashpartitioning(s_state#2, s_county#5, spark_grouping_id#11, 100), ENSURE_REQUIREMENTS, [plan_id=2]
                                          +- NativeHashAggregate HashAgg, [s_state#2, s_county#5, spark_grouping_id#11], [partial_sum(_c3#12)], [sum#13], 0
                                             +- NativeProject [s_state#2 AS s_state#2, s_county#5 AS s_county#5, spark_grouping_id#11 AS spark_grouping_id#11, UnscaledValue(ss_net_profit#9) AS _c3#12]
                                                +- !NativeExpand [[ss_net_profit#9, s_state#14, s_county#15, 0], [ss_net_profit#9, s_state#14, null, 1], [ss_net_profit#9, null, null, 3]], [ss_net_profit#9, s_state#2, s_county#5, spark_grouping_id#11]
                                                   +- NativeProject [ss_net_profit#9, s_state#14, s_county#15]
                                                      +- NativeSortMergeJoin [ss_store_sk#16], [s_store_sk#17], Inner
                                                         :- NativeSort [ss_store_sk#16 ASC NULLS FIRST], false
                                                         :  +- InputAdapter
                                                         :     +- AQEShuffleRead coalesced
                                                         :        +- ShuffleQueryStage X
                                                         :           +- NativeShuffleExchange hashpartitioning(ss_store_sk#16, 100), ENSURE_REQUIREMENTS, [plan_id=3]
                                                         :              +- NativeProject [ss_store_sk#16, ss_net_profit#9]
                                                         :                 +- NativeSortMergeJoin [ss_sold_date_sk#18], [d_date_sk#19], Inner
                                                         :                    :- NativeSort [ss_sold_date_sk#18 ASC NULLS FIRST], false
                                                         :                    :  +- InputAdapter
                                                         :                    :     +- AQEShuffleRead coalesced
                                                         :                    :        +- ShuffleQueryStage X
                                                         :                    :           +- NativeShuffleExchange hashpartitioning(ss_sold_date_sk#18, 100), ENSURE_REQUIREMENTS, [plan_id=4]
                                                         :                    :              +- NativeFilter (isnotnull(ss_sold_date_sk#18) AND isnotnull(ss_store_sk#16))
                                                         :                    :                 +- InputAdapter [#18, #16, #9]
                                                         :                    :                    +- NativeParquetScan  (FileScan parquet [ss_sold_date_sk#18,ss_store_sk#16,ss_net_profit#9] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#18), isnotnull(ss_store_sk#16)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_net_profit:decimal(7,2)>)
                                                         :                    +- NativeSort [d_date_sk#19 ASC NULLS FIRST], false
                                                         :                       +- InputAdapter
                                                         :                          +- AQEShuffleRead coalesced
                                                         :                             +- ShuffleQueryStage X
                                                         :                                +- NativeShuffleExchange hashpartitioning(d_date_sk#19, 100), ENSURE_REQUIREMENTS, [plan_id=5]
                                                         :                                   +- NativeProject [d_date_sk#19]
                                                         :                                      +- NativeFilter (((isnotnull(d_month_seq#20) AND (d_month_seq#20 >= 1200)) AND (d_month_seq#20 <= 1211)) AND isnotnull(d_date_sk#19))
                                                         :                                         +- InputAdapter [#19, #20]
                                                         :                                            +- NativeParquetScan  (FileScan parquet [d_date_sk#19,d_month_seq#20] Batched: true, DataFilters: [isnotnull(d_month_seq#20), (d_month_seq#20 >= 1200), (d_month_seq#20 <= 1211), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>)
                                                         +- NativeSort [s_store_sk#17 ASC NULLS FIRST], false
                                                            +- InputAdapter
                                                               +- AQEShuffleRead coalesced
                                                                  +- ShuffleQueryStage X
                                                                     +- NativeShuffleExchange hashpartitioning(s_store_sk#17, 100), ENSURE_REQUIREMENTS, [plan_id=6]
                                                                        +- NativeSortMergeJoin [s_state#14], [s_state#21], LeftSemi
                                                                           :- NativeSort [s_state#14 ASC NULLS FIRST], false
                                                                           :  +- InputAdapter
                                                                           :     +- AQEShuffleRead coalesced
                                                                           :        +- ShuffleQueryStage X
                                                                           :           +- NativeShuffleExchange hashpartitioning(s_state#14, 100), ENSURE_REQUIREMENTS, [plan_id=7]
                                                                           :              +- NativeFilter isnotnull(s_store_sk#17)
                                                                           :                 +- InputAdapter [#17, #15, #14]
                                                                           :                    +- NativeParquetScan  (FileScan parquet [s_store_sk#17,s_county#15,s_state#14] Batched: true, DataFilters: [isnotnull(s_store_sk#17)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string>)
                                                                           +- NativeProject [s_state#21]
                                                                              +- NativeFilter (ranking#22 <= 5)
                                                                                 +- NativeWindow [rank(_w1#23) windowspecdefinition(s_state#21, _w1#23 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#22], [s_state#21], [_w1#23 DESC NULLS LAST]
                                                                                    +- NativeWindowGroupLimit [rank(_w1#23) windowspecdefinition(s_state#21, _w1#23 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS __window_expression__#24], [s_state#21], [_w1#23 DESC NULLS LAST], 5
                                                                                       +- NativeSort [s_state#21 ASC NULLS FIRST, _w1#23 DESC NULLS LAST], false
                                                                                          +- NativeProject [s_state#21, s_state#21, MakeDecimal(sum(UnscaledValue(ss_net_profit#25))#26,17,2) AS _w1#23]
                                                                                             +- NativeHashAggregate HashAgg, ArrayBuffer(s_state#21), [s_state#21], [sum(UnscaledValue(ss_net_profit#25))], [sum(UnscaledValue(ss_net_profit#25))#26], 1
                                                                                                +- InputAdapter
                                                                                                   +- AQEShuffleRead coalesced
                                                                                                      +- ShuffleQueryStage X
                                                                                                         +- NativeShuffleExchange hashpartitioning(s_state#21, 100), ENSURE_REQUIREMENTS, [plan_id=8]
                                                                                                            +- NativeHashAggregate HashAgg, [s_state#21], [partial_sum(_c1#27)], [sum#28], 0
                                                                                                               +- NativeProject [s_state#21 AS s_state#21, UnscaledValue(ss_net_profit#25) AS _c1#27]
                                                                                                                  +- NativeProject [ss_net_profit#25, s_state#21]
                                                                                                                     +- NativeSortMergeJoin [ss_sold_date_sk#29], [d_date_sk#30], Inner
                                                                                                                        :- NativeSort [ss_sold_date_sk#29 ASC NULLS FIRST], false
                                                                                                                        :  +- InputAdapter
                                                                                                                        :     +- AQEShuffleRead coalesced
                                                                                                                        :        +- ShuffleQueryStage X
                                                                                                                        :           +- NativeShuffleExchange hashpartitioning(ss_sold_date_sk#29, 100), ENSURE_REQUIREMENTS, [plan_id=9]
                                                                                                                        :              +- NativeProject [ss_sold_date_sk#29, ss_net_profit#25, s_state#21]
                                                                                                                        :                 +- NativeSortMergeJoin [ss_store_sk#31], [s_store_sk#32], Inner
                                                                                                                        :                    :- NativeSort [ss_store_sk#31 ASC NULLS FIRST], false
                                                                                                                        :                    :  +- InputAdapter
                                                                                                                        :                    :     +- AQEShuffleRead coalesced
                                                                                                                        :                    :        +- ShuffleQueryStage X
                                                                                                                        :                    :           +- NativeShuffleExchange hashpartitioning(ss_store_sk#31, 100), ENSURE_REQUIREMENTS, [plan_id=10]
                                                                                                                        :                    :              +- NativeFilter (isnotnull(ss_store_sk#31) AND isnotnull(ss_sold_date_sk#29))
                                                                                                                        :                    :                 +- InputAdapter [#29, #31, #25]
                                                                                                                        :                    :                    +- NativeParquetScan  (FileScan parquet [ss_sold_date_sk#29,ss_store_sk#31,ss_net_profit#25] Batched: true, DataFilters: [isnotnull(ss_store_sk#31), isnotnull(ss_sold_date_sk#29)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_store_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_net_profit:decimal(7,2)>)
                                                                                                                        :                    +- NativeSort [s_store_sk#32 ASC NULLS FIRST], false
                                                                                                                        :                       +- InputAdapter
                                                                                                                        :                          +- AQEShuffleRead coalesced
                                                                                                                        :                             +- ShuffleQueryStage X
                                                                                                                        :                                +- NativeShuffleExchange hashpartitioning(s_store_sk#32, 100), ENSURE_REQUIREMENTS, [plan_id=11]
                                                                                                                        :                                   +- NativeFilter isnotnull(s_store_sk#32)
                                                                                                                        :                                      +- InputAdapter [#32, #21]
                                                                                                                        :                                         +- NativeParquetScan  (FileScan parquet [s_store_sk#32,s_state#21] Batched: true, DataFilters: [isnotnull(s_store_sk#32)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>)
                                                                                                                        +- NativeSort [d_date_sk#30 ASC NULLS FIRST], false
                                                                                                                           +- InputAdapter
                                                                                                                              +- InputAdapter [#30]
                                                                                                                                 +- AQEShuffleRead coalesced
                                                                                                                                    +- ShuffleQueryStage X
                                                                                                                                       +- ReusedExchange [d_date_sk#30], NativeShuffleExchange hashpartitioning(d_date_sk#19, 100), ENSURE_REQUIREMENTS, [plan_id=5]
+- == Initial Plan ==
   TakeOrderedAndProject(limit=100, orderBy=[lochierarchy#1 DESC NULLS LAST,CASE WHEN (lochierarchy#1 = 0) THEN s_state#2 END ASC NULLS FIRST,rank_within_parent#3 ASC NULLS FIRST], output=[total_sum#4,s_state#2,s_county#5,lochierarchy#1,rank_within_parent#3])
   +- Project [total_sum#4, s_state#2, s_county#5, lochierarchy#1, rank_within_parent#3]
      +- Window [rank(_w0#6) windowspecdefinition(_w1#7, _w2#8, _w0#6 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#3], [_w1#7, _w2#8], [_w0#6 DESC NULLS LAST]
         +- Sort [_w1#7 ASC NULLS FIRST, _w2#8 ASC NULLS FIRST, _w0#6 DESC NULLS LAST], false, 0
            +- Exchange hashpartitioning(_w1#7, _w2#8, 100), ENSURE_REQUIREMENTS, [plan_id=12]
               +- HashAggregate(keys=[s_state#2, s_county#5, spark_grouping_id#11], functions=[sum(UnscaledValue(ss_net_profit#9))], output=[total_sum#4, s_state#2, s_county#5, lochierarchy#1, _w0#6, _w1#7, _w2#8])
                  +- Exchange hashpartitioning(s_state#2, s_county#5, spark_grouping_id#11, 100), ENSURE_REQUIREMENTS, [plan_id=13]
                     +- HashAggregate(keys=[s_state#2, s_county#5, spark_grouping_id#11], functions=[partial_sum(UnscaledValue(ss_net_profit#9))], output=[s_state#2, s_county#5, spark_grouping_id#11, sum#33])
                        +- Expand [[ss_net_profit#9, s_state#14, s_county#15, 0], [ss_net_profit#9, s_state#14, null, 1], [ss_net_profit#9, null, null, 3]], [ss_net_profit#9, s_state#2, s_county#5, spark_grouping_id#11]
                           +- Project [ss_net_profit#9, s_state#14, s_county#15]
                              +- SortMergeJoin [ss_store_sk#16], [s_store_sk#17], Inner
                                 :- Sort [ss_store_sk#16 ASC NULLS FIRST], false, 0
                                 :  +- Exchange hashpartitioning(ss_store_sk#16, 100), ENSURE_REQUIREMENTS, [plan_id=14]
                                 :     +- Project [ss_store_sk#16, ss_net_profit#9]
                                 :        +- SortMergeJoin [ss_sold_date_sk#18], [d_date_sk#19], Inner
                                 :           :- Sort [ss_sold_date_sk#18 ASC NULLS FIRST], false, 0
                                 :           :  +- Exchange hashpartitioning(ss_sold_date_sk#18, 100), ENSURE_REQUIREMENTS, [plan_id=15]
                                 :           :     +- Filter (isnotnull(ss_sold_date_sk#18) AND isnotnull(ss_store_sk#16))
                                 :           :        +- FileScan parquet [ss_sold_date_sk#18,ss_store_sk#16,ss_net_profit#9] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#18), isnotnull(ss_store_sk#16)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_net_profit:decimal(7,2)>
                                 :           +- Sort [d_date_sk#19 ASC NULLS FIRST], false, 0
                                 :              +- Exchange hashpartitioning(d_date_sk#19, 100), ENSURE_REQUIREMENTS, [plan_id=16]
                                 :                 +- Project [d_date_sk#19]
                                 :                    +- Filter (((isnotnull(d_month_seq#20) AND (d_month_seq#20 >= 1200)) AND (d_month_seq#20 <= 1211)) AND isnotnull(d_date_sk#19))
                                 :                       +- FileScan parquet [d_date_sk#19,d_month_seq#20] Batched: true, DataFilters: [isnotnull(d_month_seq#20), (d_month_seq#20 >= 1200), (d_month_seq#20 <= 1211), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>
                                 +- Sort [s_store_sk#17 ASC NULLS FIRST], false, 0
                                    +- Exchange hashpartitioning(s_store_sk#17, 100), ENSURE_REQUIREMENTS, [plan_id=17]
                                       +- SortMergeJoin [s_state#14], [s_state#21], LeftSemi
                                          :- Sort [s_state#14 ASC NULLS FIRST], false, 0
                                          :  +- Exchange hashpartitioning(s_state#14, 100), ENSURE_REQUIREMENTS, [plan_id=18]
                                          :     +- Filter isnotnull(s_store_sk#17)
                                          :        +- FileScan parquet [s_store_sk#17,s_county#15,s_state#14] Batched: true, DataFilters: [isnotnull(s_store_sk#17)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string>
                                          +- Project [s_state#21]
                                             +- Filter (ranking#22 <= 5)
                                                +- Window [rank(_w1#23) windowspecdefinition(s_state#21, _w1#23 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#22], [s_state#21], [_w1#23 DESC NULLS LAST]
                                                   +- WindowGroupLimit [s_state#21], [_w1#23 DESC NULLS LAST], rank(_w1#23), 5, Final
                                                      +- Sort [s_state#21 ASC NULLS FIRST, _w1#23 DESC NULLS LAST], false, 0
                                                         +- HashAggregate(keys=[s_state#21], functions=[sum(UnscaledValue(ss_net_profit#25))], output=[s_state#21, s_state#21, _w1#23])
                                                            +- Exchange hashpartitioning(s_state#21, 100), ENSURE_REQUIREMENTS, [plan_id=19]
                                                               +- HashAggregate(keys=[s_state#21], functions=[partial_sum(UnscaledValue(ss_net_profit#25))], output=[s_state#21, sum#34])
                                                                  +- Project [ss_net_profit#25, s_state#21]
                                                                     +- SortMergeJoin [ss_sold_date_sk#29], [d_date_sk#30], Inner
                                                                        :- Sort [ss_sold_date_sk#29 ASC NULLS FIRST], false, 0
                                                                        :  +- Exchange hashpartitioning(ss_sold_date_sk#29, 100), ENSURE_REQUIREMENTS, [plan_id=20]
                                                                        :     +- Project [ss_sold_date_sk#29, ss_net_profit#25, s_state#21]
                                                                        :        +- SortMergeJoin [ss_store_sk#31], [s_store_sk#32], Inner
                                                                        :           :- Sort [ss_store_sk#31 ASC NULLS FIRST], false, 0
                                                                        :           :  +- Exchange hashpartitioning(ss_store_sk#31, 100), ENSURE_REQUIREMENTS, [plan_id=21]
                                                                        :           :     +- Filter (isnotnull(ss_store_sk#31) AND isnotnull(ss_sold_date_sk#29))
                                                                        :           :        +- FileScan parquet [ss_sold_date_sk#29,ss_store_sk#31,ss_net_profit#25] Batched: true, DataFilters: [isnotnull(ss_store_sk#31), isnotnull(ss_sold_date_sk#29)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_store_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_net_profit:decimal(7,2)>
                                                                        :           +- Sort [s_store_sk#32 ASC NULLS FIRST], false, 0
                                                                        :              +- Exchange hashpartitioning(s_store_sk#32, 100), ENSURE_REQUIREMENTS, [plan_id=22]
                                                                        :                 +- Filter isnotnull(s_store_sk#32)
                                                                        :                    +- FileScan parquet [s_store_sk#32,s_state#21] Batched: true, DataFilters: [isnotnull(s_store_sk#32)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>
                                                                        +- Sort [d_date_sk#30 ASC NULLS FIRST], false, 0
                                                                           +- Exchange hashpartitioning(d_date_sk#30, 100), ENSURE_REQUIREMENTS, [plan_id=23]
                                                                              +- Project [d_date_sk#30]
                                                                                 +- Filter (((isnotnull(d_month_seq#35) AND (d_month_seq#35 >= 1200)) AND (d_month_seq#35 <= 1211)) AND isnotnull(d_date_sk#30))
                                                                                    +- FileScan parquet [d_date_sk#30,d_month_seq#35] Batched: true, DataFilters: [isnotnull(d_month_seq#35), (d_month_seq#35 >= 1200), (d_month_seq#35 <= 1211), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>
