AdaptiveSparkPlan isFinalPlan=true
+- == Final Plan ==
   NativeTakeOrdered 100, [sum(ss_ext_sales_price)#1 DESC NULLS LAST, d_year#2 ASC NULLS FIRST, i_category_id#3 ASC NULLS FIRST, i_category#4 ASC NULLS FIRST]
   +- NativeProject [d_year#2, i_category_id#3, i_category#4, MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#5))#6,17,2) AS sum(ss_ext_sales_price)#1]
      +- NativeHashAggregate HashAgg, ArrayBuffer(d_year#2, i_category_id#3, i_category#4), [d_year#2, i_category_id#3, i_category#4], [sum(UnscaledValue(ss_ext_sales_price#5))], [sum(UnscaledValue(ss_ext_sales_price#5))#6], 3
         +- InputAdapter
            +- AQEShuffleRead coalesced
               +- ShuffleQueryStage X
                  +- NativeShuffleExchange hashpartitioning(d_year#2, i_category_id#3, i_category#4, 100), ENSURE_REQUIREMENTS, [plan_id=1]
                     +- NativeHashAggregate HashAgg, [d_year#2, i_category_id#3, i_category#4], [partial_sum(_c3#7)], [sum#8], 0
                        +- NativeProject [d_year#2 AS d_year#2, i_category_id#3 AS i_category_id#3, i_category#4 AS i_category#4, UnscaledValue(ss_ext_sales_price#5) AS _c3#7]
                           +- NativeProject [d_year#2, ss_ext_sales_price#5, i_category_id#3, i_category#4]
                              +- NativeSortMergeJoin [ss_item_sk#9], [i_item_sk#10], Inner
                                 :- NativeSort [ss_item_sk#9 ASC NULLS FIRST], false
                                 :  +- InputAdapter
                                 :     +- AQEShuffleRead coalesced
                                 :        +- ShuffleQueryStage X
                                 :           +- NativeShuffleExchange hashpartitioning(ss_item_sk#9, 100), ENSURE_REQUIREMENTS, [plan_id=2]
                                 :              +- NativeProject [d_year#2, ss_item_sk#9, ss_ext_sales_price#5]
                                 :                 +- NativeSortMergeJoin [d_date_sk#11], [ss_sold_date_sk#12], Inner
                                 :                    :- NativeSort [d_date_sk#11 ASC NULLS FIRST], false
                                 :                    :  +- InputAdapter
                                 :                    :     +- AQEShuffleRead coalesced
                                 :                    :        +- ShuffleQueryStage X
                                 :                    :           +- NativeShuffleExchange hashpartitioning(d_date_sk#11, 100), ENSURE_REQUIREMENTS, [plan_id=3]
                                 :                    :              +- NativeProject [d_date_sk#11, d_year#2]
                                 :                    :                 +- NativeFilter ((((isnotnull(d_moy#13) AND isnotnull(d_year#2)) AND (d_moy#13 = 11)) AND (d_year#2 = 2000)) AND isnotnull(d_date_sk#11))
                                 :                    :                    +- InputAdapter [#11, #2, #13]
                                 :                    :                       +- NativeParquetScan  (FileScan parquet [d_date_sk#11,d_year#2,d_moy#13] Batched: true, DataFilters: [isnotnull(d_moy#13), isnotnull(d_year#2), (d_moy#13 = 11), (d_year#2 = 2000), isnotnull(d_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_moy), IsNotNull(d_year), EqualTo(d_moy,11), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>)
                                 :                    +- NativeSort [ss_sold_date_sk#12 ASC NULLS FIRST], false
                                 :                       +- InputAdapter
                                 :                          +- AQEShuffleRead coalesced
                                 :                             +- ShuffleQueryStage X
                                 :                                +- NativeShuffleExchange hashpartitioning(ss_sold_date_sk#12, 100), ENSURE_REQUIREMENTS, [plan_id=4]
                                 :                                   +- NativeFilter (isnotnull(ss_sold_date_sk#12) AND isnotnull(ss_item_sk#9))
                                 :                                      +- InputAdapter [#12, #9, #5]
                                 :                                         +- NativeParquetScan  (FileScan parquet [ss_sold_date_sk#12,ss_item_sk#9,ss_ext_sales_price#5] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#12), isnotnull(ss_item_sk#9)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_item_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>)
                                 +- NativeSort [i_item_sk#10 ASC NULLS FIRST], false
                                    +- InputAdapter
                                       +- AQEShuffleRead coalesced
                                          +- ShuffleQueryStage X
                                             +- NativeShuffleExchange hashpartitioning(i_item_sk#10, 100), ENSURE_REQUIREMENTS, [plan_id=5]
                                                +- NativeProject [i_item_sk#10, i_category_id#3, i_category#4]
                                                   +- NativeFilter ((isnotnull(i_manager_id#14) AND (i_manager_id#14 = 1)) AND isnotnull(i_item_sk#10))
                                                      +- InputAdapter [#10, #3, #4, #14]
                                                         +- NativeParquetScan  (FileScan parquet [i_item_sk#10,i_category_id#3,i_category#4,i_manager_id#14] Batched: true, DataFilters: [isnotnull(i_manager_id#14), (i_manager_id#14 = 1), isnotnull(i_item_sk#10)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(i_manager_id), EqualTo(i_manager_id,1), IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_category_id:int,i_category:string,i_manager_id:int>)
+- == Initial Plan ==
   TakeOrderedAndProject(limit=100, orderBy=[sum(ss_ext_sales_price)#1 DESC NULLS LAST,d_year#2 ASC NULLS FIRST,i_category_id#3 ASC NULLS FIRST,i_category#4 ASC NULLS FIRST], output=[d_year#2,i_category_id#3,i_category#4,sum(ss_ext_sales_price)#1])
   +- HashAggregate(keys=[d_year#2, i_category_id#3, i_category#4], functions=[sum(UnscaledValue(ss_ext_sales_price#5))], output=[d_year#2, i_category_id#3, i_category#4, sum(ss_ext_sales_price)#1])
      +- Exchange hashpartitioning(d_year#2, i_category_id#3, i_category#4, 100), ENSURE_REQUIREMENTS, [plan_id=6]
         +- HashAggregate(keys=[d_year#2, i_category_id#3, i_category#4], functions=[partial_sum(UnscaledValue(ss_ext_sales_price#5))], output=[d_year#2, i_category_id#3, i_category#4, sum#15])
            +- Project [d_year#2, ss_ext_sales_price#5, i_category_id#3, i_category#4]
               +- SortMergeJoin [ss_item_sk#9], [i_item_sk#10], Inner
                  :- Sort [ss_item_sk#9 ASC NULLS FIRST], false, 0
                  :  +- Exchange hashpartitioning(ss_item_sk#9, 100), ENSURE_REQUIREMENTS, [plan_id=7]
                  :     +- Project [d_year#2, ss_item_sk#9, ss_ext_sales_price#5]
                  :        +- SortMergeJoin [d_date_sk#11], [ss_sold_date_sk#12], Inner
                  :           :- Sort [d_date_sk#11 ASC NULLS FIRST], false, 0
                  :           :  +- Exchange hashpartitioning(d_date_sk#11, 100), ENSURE_REQUIREMENTS, [plan_id=8]
                  :           :     +- Project [d_date_sk#11, d_year#2]
                  :           :        +- Filter ((((isnotnull(d_moy#13) AND isnotnull(d_year#2)) AND (d_moy#13 = 11)) AND (d_year#2 = 2000)) AND isnotnull(d_date_sk#11))
                  :           :           +- FileScan parquet [d_date_sk#11,d_year#2,d_moy#13] Batched: true, DataFilters: [isnotnull(d_moy#13), isnotnull(d_year#2), (d_moy#13 = 11), (d_year#2 = 2000), isnotnull(d_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(d_moy), IsNotNull(d_year), EqualTo(d_moy,11), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
                  :           +- Sort [ss_sold_date_sk#12 ASC NULLS FIRST], false, 0
                  :              +- Exchange hashpartitioning(ss_sold_date_sk#12, 100), ENSURE_REQUIREMENTS, [plan_id=9]
                  :                 +- Filter (isnotnull(ss_sold_date_sk#12) AND isnotnull(ss_item_sk#9))
                  :                    +- FileScan parquet [ss_sold_date_sk#12,ss_item_sk#9,ss_ext_sales_price#5] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#12), isnotnull(ss_item_sk#9)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_item_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>
                  +- Sort [i_item_sk#10 ASC NULLS FIRST], false, 0
                     +- Exchange hashpartitioning(i_item_sk#10, 100), ENSURE_REQUIREMENTS, [plan_id=10]
                        +- Project [i_item_sk#10, i_category_id#3, i_category#4]
                           +- Filter ((isnotnull(i_manager_id#14) AND (i_manager_id#14 = 1)) AND isnotnull(i_item_sk#10))
                              +- FileScan parquet [i_item_sk#10,i_category_id#3,i_category#4,i_manager_id#14] Batched: true, DataFilters: [isnotnull(i_manager_id#14), (i_manager_id#14 = 1), isnotnull(i_item_sk#10)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/<warehouse_dir>], PartitionFilters: [], PushedFilters: [IsNotNull(i_manager_id), EqualTo(i_manager_id,1), IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_category_id:int,i_category:string,i_manager_id:int>
